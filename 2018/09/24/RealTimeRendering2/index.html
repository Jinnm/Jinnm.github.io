<!DOCTYPE html><html><head><meta name="generator" content="Hexo 3.8.0"><meta charset="utf-8"><title>RealTimeRendering Ch.2 | Codemoph</title><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1"><meta name="description" content="ArchitectureThe speed of the pipelines is determined by the speed of the slowest stage called bottleneck. The fatest is called starved, because it needs to wait for other stages to be done.A coarse di"><meta name="keywords" content="ComputerGraphics"><meta property="og:type" content="article"><meta property="og:title" content="RealTimeRendering Ch.2"><meta property="og:url" content="https://jinnm.github.io/2018/09/24/RealTimeRendering2/index.html"><meta property="og:site_name" content="Codemoph"><meta property="og:description" content="ArchitectureThe speed of the pipelines is determined by the speed of the slowest stage called bottleneck. The fatest is called starved, because it needs to wait for other stages to be done.A coarse di"><meta property="og:locale" content="en"><meta property="og:image" content="http://ws3.sinaimg.cn/large/006tNbRwgy1fvky38kt49j312u08qabi.jpg"><meta property="og:image" content="http://ws3.sinaimg.cn/large/006tNbRwgy1fvlumsdzcij314806s74z.jpg"><meta property="og:image" content="http://ws1.sinaimg.cn/large/006tNbRwgy1fvlycbvpb0j31as09c0x5.jpg"><meta property="og:image" content="http://ws3.sinaimg.cn/large/006tNbRwgy1fvm5dlvnspj315k0cgtaa.jpg"><meta property="og:image" content="http://ws3.sinaimg.cn/large/006tNbRwly1fwejqvij03j30xe07yjt2.jpg"><meta property="og:image" content="http://ws2.sinaimg.cn/large/006tNbRwly1fwept51i6qj31460s87bu.jpg"><meta property="og:updated_time" content="2019-05-30T07:14:21.748Z"><meta name="twitter:card" content="summary"><meta name="twitter:title" content="RealTimeRendering Ch.2"><meta name="twitter:description" content="ArchitectureThe speed of the pipelines is determined by the speed of the slowest stage called bottleneck. The fatest is called starved, because it needs to wait for other stages to be done.A coarse di"><meta name="twitter:image" content="http://ws3.sinaimg.cn/large/006tNbRwgy1fvky38kt49j312u08qabi.jpg"><link rel="icon" href="/favicon.png"><link href="https://fonts.googleapis.com/css?family=Lato:400,400i,700" rel="stylesheet"><link rel="stylesheet" href="/icomoon/style.css"><link rel="stylesheet" href="/style.css"></head><body><div class="site-wrapper"><div id="loading-bar-wrapper"><div id="loading-bar"></div></div><script>document.getElementById("loading-bar").style.width="20%"</script><header id="header" class="site-header clearfix"><a class="logo square clearfix" href="/"><span class="b">C </span><span class="w">o </span><span class="b">d </span><span class="w">e </span><span class="b">m </span><span class="b">o </span><span class="w">p </span><span class="b">h </span></a><a class="me square site-nav-switch clearfix"><span class="b"><span class="icon icon-menu"></span></span></a></header><script>document.getElementById("loading-bar").style.width="40%"</script><main id="main" class="clearfix"><article id="post-RealTimeRendering2" class="article white-box article-type-post" itemscope itemprop="blogPost"><header class="article-header"><h1 class="article-title" itemprop="name">RealTimeRendering Ch.2</h1><div class="article-meta">Posted on <time class="article-time" datetime="2018-09-24T13:01:43.000Z" itemprop="datePublished">Sep 24, 2018</time></div></header><div class="article-entry" itemprop="articleBody"><h3 id="Architecture"><a href="#Architecture" class="headerlink" title="Architecture"></a>Architecture</h3><p>The speed of the pipelines is determined by the speed of the slowest stage called <strong>bottleneck</strong>. The fatest is called <strong>starved</strong>, because it needs to wait for other stages to be done.</p><p>A coarse division of the real-time rendering pipeline into four main stages: <strong>application</strong>, <strong>geometry processing</strong>, <strong>rasterization</strong>, and <strong>pixel processing</strong>.<br><img src="http://ws3.sinaimg.cn/large/006tNbRwgy1fvky38kt49j312u08qabi.jpg" alt></p><h3 id="Application-Stage"><a href="#Application-Stage" class="headerlink" title="Application Stage"></a>Application Stage</h3><p>Running on CPUs.</p><p>But some application work can be performed by the GPU, using a separate mode called a <strong>compute shader</strong>. This mode treats the GPU as a highly parallel general processor, ignoring its special functionality meant speciﬁcally for rendering graphics.</p><p>Some of the tasks traditionally performed on the CPU include <strong>collision detection</strong>, global acceleration algorithms, animation, physics simulation, and many others, depending on the type of application.</p><p>The application stage is also the place to take care of input from other sources, such as the keyboard, the mouse, or a head-mounted display.</p><p>Acceleration algorithms, such as particular culling algorithms (Chapter 19), are also implemented here, along with whatever else the rest of the pipeline cannot handle.</p><p>Output: <strong>Rendering Primitives</strong>, i.e., points, lines, and triangles, that might eventually end up on the screen.</p><h3 id="Geometry-Processing"><a href="#Geometry-Processing" class="headerlink" title="Geometry Processing"></a>Geometry Processing</h3><p>Running on GPUs.</p><p>The geometry processing stage on the GPU is responsible for most of the per-triangle and per-vertex operations.</p><p>This stage is further divided into the following functional stages: <strong>vertex shading</strong>, <strong>projection</strong>, <strong>optional vertex processing</strong>, <strong>clipping</strong>, and <strong>screen mapping</strong><br><img src="http://ws3.sinaimg.cn/large/006tNbRwgy1fvlumsdzcij314806s74z.jpg" alt></p><h5 id="Vertex-Shading"><a href="#Vertex-Shading" class="headerlink" title="Vertex Shading"></a>Vertex Shading</h5><p>Two main tasks:</p><ul><li><p>computing the position for a vertex, also called <strong>MVP</strong><br><img src="http://ws1.sinaimg.cn/large/006tNbRwgy1fvlycbvpb0j31as09c0x5.jpg" alt></p></li><li><p>evaluate whatever the programmer may like to have as vertex output data (such as a normal and texture coordinates)<br>The operation of determining the eﬀect of a light on a material is known as shading. Shading may be performed on a model’s vertices or during per-pixel processing.<br>A variety of material data can be stored at each vertex, such as the point’s location, a normal, a color.</p></li></ul><h5 id="Projection"><a href="#Projection" class="headerlink" title="Projection"></a>Projection</h5><p>Projection is expressed as a matrix.</p><ul><li><p>orthographic(parallel) projection<br>Transforming a rectangular box to a unit cube, and parallel lines remain parallel after the transform.</p></li><li><p>perspective projection<br>Perspective Frustum(截头视椎体)</p></li></ul><p>Then follows Normalized Device Coordinates(NDC, 坐标归一化).</p><p>Both orthographic and perspective transforms can be constructed with 4 × 4 matrices.</p><p>They are called projections because after display, the z-coordinate is not stored in the image generated but is stored in a z-buﬀer. In this way, the models are projected from three to two dimensions.</p><h5 id="Optional-Vertex-Processing"><a href="#Optional-Vertex-Processing" class="headerlink" title="Optional Vertex Processing"></a>Optional Vertex Processing</h5><p>Their use depends both on the capabilities of the hardware—not all GPUs have them—and the desires of the programmer.</p><ul><li><p>Tessellation(图元细分)<br>The camera for the scene can be used to determine how many triangles are generated: many when the patch is close, few when it is far away.</p></li><li><p>Geometry Shader<br>It can be used for particle generation(粒子生成).<br>Imagine simulating a ﬁreworks explosion. Each ﬁreball could be represented by a point, a single vertex. The geometry shader can take each point and turn it into a square (made of two triangles) that faces the viewer and covers several pixels, so providing a more convincing primitive for us to shade.</p></li><li><p>Stream Output<br>It can be used for particle simulations(粒子模拟).<br>This stage lets us use the GPU as a geometry engine. Instead of sending our processed vertices down the rest of the pipeline to be rendered to the screen, at this point we can optionally output these to an array for further processing. These data can be used by the CPU, or the GPU itself, in a later pass.</p></li></ul><p>These three stages are performed in this order—tessellation, geometry shading, and stream output—and each is optional.</p><h5 id="Clipping"><a href="#Clipping" class="headerlink" title="Clipping"></a>Clipping</h5><p>Only the primitives wholly or partially inside the view volume need to be passed on to subsequent stage.</p><p>The primitives that are partially inside the view volume require clipping. And some new vertices will be located at the intersection between the line and the view volume.</p><p>The advantage of performing the view transformation and projection before clipping is that it makes the clipping problem consistent; primitives are always clipped against the unit cube.</p><p>Finally, perspective division(division by w) is performed, which places the resulting triangles’ positions into three-dimensional normalized device coordinates.</p><h5 id="Screen-Mapping"><a href="#Screen-Mapping" class="headerlink" title="Screen Mapping"></a>Screen Mapping</h5><p>The coordinates are still three-dimensional when entering this stage.</p><p>The x- and y-coordinates of each primitive are transformed to form <strong>screen coordinates</strong>. Screen coordinates together with the z-coordinates are also called <strong>window coordinates</strong>.<br><img src="http://ws3.sinaimg.cn/large/006tNbRwgy1fvm5dlvnspj315k0cgtaa.jpg" alt></p><p>The last step in the geometry stage is to convert from NDC to window coordinates.</p><h3 id="Rasterization"><a href="#Rasterization" class="headerlink" title="Rasterization"></a>Rasterization</h3><p>Rasterization, also called <strong>scan conversion</strong>, is thus the conversion from two-dimensional vertices in screen space—each with a z-value (depth value) and various shading information asso- ciated with each vertex—into pixels on the screen.<br><img src="http://ws3.sinaimg.cn/large/006tNbRwly1fwejqvij03j30xe07yjt2.jpg" alt></p><h5 id="Triangle-Setup"><a href="#Triangle-Setup" class="headerlink" title="Triangle Setup"></a>Triangle Setup</h5><p>In this stage the diﬀerentials, edge equations, and other data for the triangle are computed. Fixed- function hardware is used for this task.</p><h5 id="Triangle-Traversal"><a href="#Triangle-Traversal" class="headerlink" title="Triangle Traversal"></a>Triangle Traversal</h5><p>Finding which samples or pixels are inside a triangle is often called triangle traversal.</p><h3 id="Pixel-Processing"><a href="#Pixel-Processing" class="headerlink" title="Pixel Processing"></a>Pixel Processing</h3><p>At this point, all the pixels that are considered inside a triangle or other primitive have been found as a consequence of the combination of all the previous stages.</p><p>Pixel processing is the stage where per-pixel or per-sample computations and operations are performed on pixels or samples that are inside a primitive.</p><blockquote><p>In computer graphics, a sample is an intersection of channel and a pixel.</p></blockquote><h5 id="Pixel-Shading"><a href="#Pixel-Shading" class="headerlink" title="Pixel Shading"></a>Pixel Shading</h5><p>The end product is a color value for each fragment. And this stage is executed by programmable GPU cores. The programmer supplies a program for the fragment shader, which can contain any desired computations.</p><p>Texturing is employed here.</p><h5 id="Merging"><a href="#Merging" class="headerlink" title="Merging"></a>Merging</h5><p>Combine the fragment color produced by the pixel shading stage with the color currently stored in the buﬀer.</p><p>Unlike the shading stage, the GPU subunit that performs this stage is typically not fully programmable. However, it is highly conﬁgurable, enabling various eﬀects.</p><p>This stage is also responsible for resolving visibility.</p><ul><li><p>Alpha Test</p></li><li><p>Stencil Buﬀer</p></li><li><p>Frame Buffer<br>It generally consists of all the buﬀers on a system</p></li><li><p>Depth Test<br>It is done with the z-buﬀer algorithm. However, z-buﬀer algorithm cannot be used for partially transparent primitives. These must be rendered after all opaque primitives, and in back-to-front order, or using a separate order-independent algorithm (Section 5.5). Transparency is one of the major weaknesses of the basic z-buﬀer.</p></li><li><p>Double Buﬀer</p></li></ul><h3 id="Through-the-Pipeline"><a href="#Through-the-Pipeline" class="headerlink" title="Through the Pipeline"></a>Through the Pipeline</h3><p><img src="http://ws2.sinaimg.cn/large/006tNbRwly1fwept51i6qj31460s87bu.jpg" alt></p></div><div class="article-tags"><a class="tag-link" href="/tagsfol/ComputerGraphics/">ComputerGraphics</a></div></article><script>document.getElementById("loading-bar").style.width="60%"</script></main><footer id="footer" class="clearfix"><div class="search"><form name="searchform" id="searchform" class="u-search-form"><input type="text" id="searchinput" class="u-search-input st-default-search-input" data-list-highlight="true" data-list-value-completion="true" placeholder="Looking for something?"> <button type="submit" id="u-search-btn-submit" class="u-search-btn-submit"><span class="icon icon-search"></span></button></form></div><div>&copy; <a href="https://jinnm.github.io">Codemoph</a> Theme by <a href="http://artifact.me/" target="_blank">Art Chen</a>.</div><div>Powered by <a href="https://hexo.io/" rel="external">Hexo</a>.</div></footer><script>document.getElementById("loading-bar").style.width="80%"</script><div class="overlay"></div></div><div class="site-sidebar"><div class="sidebar-switch clearfix" style="display:none"><a class="dark-btn active" data-toggle="toc"><span class="icon icon-list"></span> <span class="text">Index</span> </a><a class="dark-btn" data-toggle="bio"><span class="icon icon-person"></span> <span class="text">Bio</span></a></div><div class="site-toc" style="display:none"><div class="no-index">No Index</div></div><div class="site-bio show" style="display:block"><div class="about-me clearfix"><div class="avatar"><img src="/img/avatar.png"></div><div class="info"><a class="name dark-btn" href="/about">Jinnm</a></div><div class="info"><span class="item desc"></span></div></div><div class="social clearfix"></div><div class="shortcuts clearfix"><div class="bk"><a href="#header" class="dark-btn window-nav"><span class="icon icon-chevron-thin-up"></span> <span class="text">Back to Top</span></a></div><div class="bk"><a href="#footer" class="dark-btn window-nav"><span class="icon icon-chevron-thin-down"></span> <span class="text">Go to Bottom</span></a></div></div></div></div><script type="text/javascript">var GOOGLE_CUSTOM_SEARCH_API_KEY="",GOOGLE_CUSTOM_SEARCH_ENGINE_ID="",ALGOLIA_API_KEY="",ALGOLIA_APP_ID="",ALGOLIA_INDEX_NAME="",AZURE_SERVICE_NAME="",AZURE_INDEX_NAME="",AZURE_QUERY_KEY="",BAIDU_API_ID="",SEARCH_SERVICE="hexo"</script><script src="https://code.jquery.com/jquery-2.1.4.min.js"></script><script>window.jQuery||document.write('<script src="/js/jquery.js"><\/script>')</script><script src="/js/search.js"></script><script src="/js/app.js"></script><script>document.getElementById("loading-bar").style.width="100%"</script><script type="text/x-mathjax-config">MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });</script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML"></script></body></html>